
@article{zhu2025auditingblackboxllmapis,
      abbr={Preprint},
      title={Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test}, 
      author={Xiaoyuan Zhu and Yaowen Ye and Tianyi Qiu and Hanlin Zhu and Sijun Tan and Ajraf Mannan and Jonathan Michala and Raluca Ada Popa and Willie Neiswanger},
      selected={true},
      year={2025},
      month={},
      journal={arXiv preprint arXiv:2506.06975},
      arxiv={2506.06975},
      url={https://arxiv.org/abs/2506.06975}, 
}

@article{zhu2025llmunlearningexpertcurated,
      abbr={COLM},
      title={LLM Unlearning Without an Expert Curated Dataset}, 
      author={Xiaoyuan Zhu and Muru Zhang and Ollie Liu and Robin Jia and Willie Neiswanger},
      eprint={2508.06595},
      selected={true},
      year={2025},
      month={},
      journal={In The Conference on Language Modeling},
      arxiv={2508.06595}, 
      code={https://github.com/xyzhu123/Synthetic_Textbook},
      poster={https://drive.google.com/file/d/1zxbcjudztgsUWzcYGp30AR1GtlPJ81_-/view?usp=sharing},
}

@article{kian-etal-2025-using,
    abbr={NAACL},
    title = "Using Linguistic Entrainment to Evaluate Large Language Models for Use in Cognitive Behavioral Therapy",
    author = "Kian, Mina  and
      Shrestha, Kaleen  and
      Fischer, Katrin  and
      Zhu, Xiaoyuan  and
      Ong, Jonathan  and
      Trehan, Aryan  and
      Wang, Jessica  and
      Chang, Gloria  and
      Arnold, S{\'e}b  and
      Mataric, Maja",
    year = "2025",
    pdf = "https://aclanthology.org/2025.findings-naacl.430/",
    journal = "In the Findings of the Association for Computational Linguistics: NAACL",
    selected = {true},
}

@article{li2024wmdp,
      abbr={ICML},
      title={The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning},
      author={WMDP Team},
      year={2024},
      journal={In The International Conference on Machine Learning},
      selected={true},
      arxiv={2403.03218},
      code={https://github.com/centerforaisafety/wmdp},
      website={https://www.wmdp.ai/},
}

@article{Shi2024HowCL,
  abbr={AAAI-SS},
  title={How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey},
  author={Zhonghao Shi and Ellen Landrum and Amy O'Connell and Mina J. Kian and Leticia Pinto-Alva and Kaleen Shrestha and Xiaoyuan Zhu and Maja Matari'c},
  journal={In the AAAI Symposium Series},
  year={2024},
  selected={true},
  arxiv={2404.00938}
}

@article{thawani2023learntokenswordpooledtokenization,
      abbr={EMNLP},
      title={Learn Your Tokens: Word-Pooled Tokenization for Language Modeling}, 
      author={Avijit Thawani and Saurabh Ghanekar and Xiaoyuan Zhu and Jay Pujara},
      year={2023},
      arxiv={2310.11628},
      code={https://github.com/avi-otterai/eTok},
      journal={In the Findings of The Conference on Empirical Methods in Natural Language Processing},
      selected={true},
}

@article{Chang_2023, 
   abbr={Interspeech},
   title={Multimodal Speech Recognition for Language-Guided Embodied Agents},
   author={Chang, Allen and Zhu, Xiaoyuan and Monga, Aarav and Ahn, Seoho and Srinivasan, Tejas and Thomason, Jesse},
   year={2023},
   arxiv={2302.14030},
   selected={true},
   journal={In the Interspeech Conference},
   code={https://github.com/Cylumn/embodied-multimodal-asr},
   
}